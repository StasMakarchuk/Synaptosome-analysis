% This script trains and tests a support vector machine (SVM) using the
% output data from the compareConditions script, where an extra column
% 'Class' has been added in the table manually in which the values 1 or 0
% where assigned to disperse and compact synaptosomes respectively.
% 
% Link to a tutorial on using fitcsvm function in matlab:
% https://www.youtube.com/watch?v=q778MSq21vU
% 
% Author: Ezra Bruggeman, Laser Analytics Group
% Last updated on 30 Sept 2018


clear all
close all
clc


%% Parameters

path_data = '/Users/Ezra/Desktop/data_37C_classified.mat';

fraction_train = 0.80; % fraction of data used for training 

fix_rng = 0; % 1 to fix random number generator (for reproducible results)

% number of features used to predict label (can be visualized for
% nfeatures = 2 and 3)
nfeatures = 3;


%% 1) Prepare dataset

% Load data
load(path_data);

% Remove rows that have -1 value in any of the Ripley's columns
data(ismember(data.clustersizeRC,-1),:)=[];
data(ismember(data.clustersizeGC,-1),:)=[];
data(ismember(data.clustersizeBC,-1),:)=[];
data(ismember(data.interclusterdistRG,-1),:)=[];
data(ismember(data.interclusterdistRB,-1),:)=[];
data(ismember(data.interclusterdistGB,-1),:)=[];

% Convert categorical labels 'phys', 'egta' and 'egtak' to integers to matrix
condition = grp2idx(table2array(data(:,1)));
condition = array2table(condition,'VariableNames',{'condition'});

% Get the labels
y = cell2mat(data.Class);

% Only select useful measurements from data table
%X = [data(:,1:7) data(:,12:13) data(:,8:11) data(:,14:end)];
X = [condition data(:,12:end)];


%% 2) Divide in training and test set

if fix_rng; rng default; end

rand_num = randperm(length(y));

% Get number of rows to be used for training
n_train = floor(fraction_train*length(y));

% Seperate data into a training and test set
X_train = X(rand_num(1:n_train),:);
y_train = y(rand_num(1:n_train),:);
X_test  = X(rand_num(n_train+1:end),:);
y_test  = y(rand_num(n_train+1:end),:);


%% 3) Prepare validation set out of training set (k-fold cross-validation)

c = cvpartition(y_train,'k',5);


%% 4) Feature selection

% Some display options
opts = statset('display','iter');

% Fun compares the prediction of the labels of some test data feeded into
% the model generated by fitcsvm with the true test labels. So it will
% check how 'wrong' the model was by summing the errors
fun = @(train_data, train_labels, test_data, test_labels)...
    sum(predict(fitcsvm(train_data, train_labels, 'KernelFunction','rbf'), test_data) ~= test_labels);

% Perform the feature selection (This one uses forward sequential feature
% selection by default. You can add 'direction','backward' as options;)
[fs,history] = sequentialfs(fun, table2array(X_train), y_train, 'cv', c, 'options', opts, 'nfeatures', nfeatures);
% You can also specify which columns are definitely included, or definitely
% not included.
% 'fs' gives you which final columns are included
% 'history' gives you the history of different combinations of columns that
% were tried out before


%% 5) Finding the best hyper parameters for the classification

% Use only the features that were found to be most useful for 
% classification
X_train_with_best_features = X_train(:,fs);

% Get the SVM model
SVMModel = fitcsvm(X_train_with_best_features,y_train);


%% 6) Test the data with the test set

% Use only the features that were found to be most useful for 
% classification
X_test_with_best_features = X_test(:,fs);

% Let model predict labels of test data
y_test_predicted = predict(SVMModel, X_test_with_best_features);

% Calculate accurcay with which model can predict labels
accuracy = sum(y_test_predicted == y_test)/length(y_test)*100;
disp(['Model predicted the right label ' num2str(accuracy) '% of the time.'])


%% 7) Plot results

if nfeatures == 2
    
    % Plot training data
    figure(1);
    hgscatter = gscatter(table2array(X_train_with_best_features(:,1)),...
                         table2array(X_train_with_best_features(:,2)),...
                         y_train);
    hold on;
    h_sv = plot(SVMModel.SupportVectors(:,1),...
                SVMModel.SupportVectors(:,2),...
                'ko','markersize',8);
    xlabel(SVMModel.PredictorNames(1))
    ylabel(SVMModel.PredictorNames(2))
    set(gca,'fontsize',14);
    legend('compact','disperse')
    
    % Plot test data with predicted labels
    X_predicted_0 = table2array(X_test_with_best_features(y_test_predicted==0,:));
    X_predicted_1 = table2array(X_test_with_best_features(y_test_predicted==1,:));

    figure(2);
    scatter(X_predicted_0(:,1),X_predicted_0(:,2),200,'.r');
    hold on
    scatter(X_predicted_1(:,1),X_predicted_1(:,2),200,'.c');
    hold off
    xlabel(SVMModel.PredictorNames(1))
    ylabel(SVMModel.PredictorNames(2))
    title({'Test data (predicted labels)','red = compact; blue = disperse'})
    set(gca,'fontsize',14);
    
    
elseif nfeatures == 3
    
    % Plot training data
    X_train_0 = table2array(X_train_with_best_features(y_train==0,:));
    X_train_1 = table2array(X_train_with_best_features(y_train==1,:));

    figure(1);
    scatter3(X_train_0(:,1),X_train_0(:,2),X_train_0(:,3),200,'.r');
    hold on
    scatter3(X_train_1(:,1),X_train_1(:,2),X_train_1(:,3),200,'.c');
    hold off
    xlabel(SVMModel.PredictorNames(1))
    ylabel(SVMModel.PredictorNames(2))
    zlabel(SVMModel.PredictorNames(3))
    title({'Training data (true labels)','red = compact; blue = disperse'})
    set(gca,'fontsize',14);


    % Plot test data with predicted labels
    X_predicted_0 = table2array(X_test_with_best_features(y_test_predicted==0,:));
    X_predicted_1 = table2array(X_test_with_best_features(y_test_predicted==1,:));

    figure(2);
    scatter3(X_predicted_0(:,1),X_predicted_0(:,2),X_predicted_0(:,3),200,'.r');
    hold on
    scatter3(X_predicted_1(:,1),X_predicted_1(:,2),X_predicted_1(:,3),200,'.c');
    hold off
    xlabel(SVMModel.PredictorNames(1))
    ylabel(SVMModel.PredictorNames(2))
    zlabel(SVMModel.PredictorNames(3))
    title({'Test data (predicted labels)','red = compact; blue = disperse'})
    set(gca,'fontsize',14);

end